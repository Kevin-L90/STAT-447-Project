a = simulate(Bern(0.5))
intercept = simulate(Norm(0, 1))
if (a == 0) {
slope = 0
} else {
slope = simulate(Norm(0, 1))
}
for (i in 1:n) {
prob = plogis(intercept + slope * xs[i])
observe(success_indicators[i], Bern(prob))
}
success = plogis(intercept + slope * (n + 1))
return(c(intercept, slope, success))
}
posterior_samples = posterior_particles(logistic_regression2, 1000)
nexts = length(success_indicators) + 1
probs = plogis(posterior_samples$samples[,1] + posterior_samples$samples[,2] * nexts)
sum(probs * posterior_samples$weights) / sum(posterior_samples$weights)
knitr::opts_chunk$set(echo = TRUE)
#if you do not have the package, type install.packages("name_of_the_package")
library(knitr)
library(tseries)
data = read.csv("souvenir.txt")
View(data)
data = read.csv("souvenir.txt")
datats = ts(data, start = c(1987, 1), frequency = 12)
plot(datats)
data = read.csv("souvenir.txt")
datats = ts(data, start = c(1987, 1), frequency = 12)
plot(datats)
acf(datats)
data = read.csv("souvenir.txt")
datats = ts(data, start = c(1987, 1), frequency = 12)
plot(datats)
acf(datats)
data = read.csv("souvenir.txt")
datats = ts(data, start = c(1987, 1), frequency = 12)
plot(datats, xlab = 'Year', ylab = '$', main = 'Times series of Souvenir sales')
acf(datats, main = 'ACF of Souvenir sales')
data = read.csv("souvenir.txt")
datats = ts(data, start = 1987, frequency = 12)
plot(datats, xlab = 'Year', ylab = '$', main = 'Times series of Souvenir sales')
acf(datats, main = 'ACF of Souvenir sales')
data = read.csv("souvenir.txt")
datats = ts(data, start = 1987, frequency = 12)
plot(datats, xlab = 'Year', ylab = '$', main = 'Times series of Souvenir sales')
acf(datats, main = 'ACF of Souvenir sales', lag = 12)
data = read.csv("souvenir.txt")
datats = ts(data, start = 1987, frequency = 12)
plot(datats, xlab = 'Year', ylab = '$', main = 'Times series of Souvenir sales')
acf(datats, main = 'ACF of Souvenir sales', lag = 24)
data = read.csv("souvenir.txt")
datats = ts(data, start = 1987, frequency = 12)
plot(datats, xlab = 'Year', ylab = '$', main = 'Times series of Souvenir sales')
acf(datats, main = 'ACF of Souvenir sales', lag = 60)
knitr::opts_chunk$set(echo = TRUE)
#if you do not have the package, type install.packages("name_of_the_package")
library(knitr)
library(tseries)
train = window(souvenir_ts, end = c(1993, 1))
train = window(datats, end = c(1993, 1))
data = read.csv("souvenir.txt")
datats = ts(data, start = 1987, frequency = 12)
plot(datats, xlab = 'Year', ylab = '$', main = 'Times series of Souvenir sales')
acf(datats, main = 'ACF of Souvenir sales', lag = 60)
train = window(datats, end = c(1993, 1))
test = window(datats, start = c(1993, 2))
hw = HoltWinters(train, season = "multiplicative")
train = window(datats, end = c(1993, 1))
test = window(datats, start = c(1993, 2))
hw = HoltWinters(train, season = "multiplicative")
print(hw)
plot(hw)
fitted = fitted(hw)
plot(fitted[,1], main="Level")
plot(fitted[,2], main="Trend")
plot(fitte[,3], main="Seasonal Effect")
fitted = fitted(hw)
plot(fitted[,1], main="Level")
plot(fitted[,2], main="Trend")
plot(fitted[,3], main="Seasonal Effect")
pred = predict(hw, n.ahead = 11, prediction.interval = TRUE, level = 0.95)
ts.plot(test_ts, predictions[,1], predictions[,2], predictions[,3], col=c("black", "blue", "red", "red"), lty=c(1,1,2,2))
pred = predict(hw, n.ahead = 11, prediction.interval = TRUE, level = 0.95)
ts.plot(test, pred[,1], pred[,2], pred[,3], col=c("black", "blue", "red", "red"), lty=c(1,1,2,2))
pred[1:3,1]
remove.packages("rstan")
if (file.exists(".RData")) file.remove(".RData")
Sys.setenv(DOWNLOAD_STATIC_LIBV8 = 1) # only necessary for Linux without the nodejs library / headers
install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies = TRUE)
example(stan_model, package = "rstan", run.dontrun = TRUE)
example(stan_model, package = "rstan", run.dontrun = TRUE)
example(stan_model, package = "rstan", run.dontrun = TRUE)
knitr::opts_chunk$set(echo = TRUE)
#if you do not have the package, type install.packages("name_of_the_package")
library(knitr)
library(tseries)
library(rstan)
fit = stan(
seed = 123,
file = "beta_binomial.stan",
data = list(n=3, k=3),
iter = 1000
)
print(fit)
suppressPackageStartupMessages(require(ggplot2))
suppressPackageStartupMessages(require(dplyr))
df = read.csv(
"https://raw.githubusercontent.com/UBC-Stat-ML/web447/1e345149a5b698ccdf0a7e9b0aeabec2463c50ca/data/sunspots-SN_m_tot_V2.0.csv",
sep = ";", header=FALSE) %>%
mutate(count = ceiling(V4)) %>%
rename(year = V3) %>%
filter(year > 2005)
count = as.integer(df$count)
time = as.numeric(df$year)
data = list(
N = length(count),
count = count,
time = time
)
init_fun <- function() {
list(theta1 = 40, theta2 = 1.0, theta3 = 0.25)
}
fit = stan(
seed = 123,
file = "poisson.stan",
data = data,
init = init_fun(),
iter = 2500
)
print(fit)
str(data)
suppressPackageStartupMessages(require(ggplot2))
suppressPackageStartupMessages(require(dplyr))
df = read.csv(
"https://raw.githubusercontent.com/UBC-Stat-ML/web447/1e345149a5b698ccdf0a7e9b0aeabec2463c50ca/data/sunspots-SN_m_tot_V2.0.csv",
sep = ";", header=FALSE) %>%
mutate(count = ceiling(V4)) %>%
rename(year = V3) %>%
filter(year > 2005)
count = as.integer(df$count)
time = as.numeric(df$year)
data = list(
N = length(count),
counts = count,
time = time
)
init_fun <- function() {
list(theta1 = 40, theta2 = 1.0, theta3 = 0.25)
}
fit = stan(
seed = 123,
file = "poisson.stan",
data = data,
init = init_fun(),
iter = 2500
)
print(fit)
suppressPackageStartupMessages(require(ggplot2))
suppressPackageStartupMessages(require(dplyr))
df = read.csv(
"https://raw.githubusercontent.com/UBC-Stat-ML/web447/1e345149a5b698ccdf0a7e9b0aeabec2463c50ca/data/sunspots-SN_m_tot_V2.0.csv",
sep = ";", header=FALSE) %>%
mutate(count = ceiling(V4)) %>%
rename(year = V3) %>%
filter(year > 2005)
count = as.integer(df$count)
time = as.numeric(df$year)
data = list(
n = length(count),
counts = count,
time = time
)
init_fun <- function() {
list(theta1 = 40, theta2 = 1.0, theta3 = 0.25)
}
fit = stan(
seed = 123,
file = "poisson.stan",
data = data,
init = init_fun(),
iter = 2500
)
print(fit)
suppressPackageStartupMessages(require(ggplot2))
suppressPackageStartupMessages(require(dplyr))
df = read.csv(
"https://raw.githubusercontent.com/UBC-Stat-ML/web447/1e345149a5b698ccdf0a7e9b0aeabec2463c50ca/data/sunspots-SN_m_tot_V2.0.csv",
sep = ";", header=FALSE) %>%
mutate(count = ceiling(V4)) %>%
rename(year = V3) %>%
filter(year > 2005)
count = as.integer(df$count)
time = as.numeric(df$year)
data = list(
n = length(count),
counts = count,
time = time
)
init_fun <- function() {
list(theta1 = 40, theta2 = 1.0, theta3 = 0.25)
}
fit = stan(
seed = 123,
file = "poisson.stan",
data = data,
init = init_fun(),
iter = 2500
)
print(fit)
fit <- stan("poisson.stan", data = data_list, iter = 2500, chains = 4)
fit <- stan("poisson.stan", data = data, iter = 2500, chains = 4)
setwd("C:/Users/kevin/OneDrive/Desktop/STAT 447/Exercises/Exercise 7")
fit <- stan("your_model.stan", data = data_list, iter = 2500, chains = 4)
fit <- stan("your_model.stan", data = data, iter = 2500, chains = 4)
setwd("C:/Users/kevin/OneDrive/Desktop/STAT 447/Exercises/Exercise 7")
fit <- stan("poisson.stan", data = data, iter = 2500, chains = 4)
print(fit)
suppressPackageStartupMessages(require(ggplot2))
suppressPackageStartupMessages(require(dplyr))
df = read.csv(
"https://raw.githubusercontent.com/UBC-Stat-ML/web447/1e345149a5b698ccdf0a7e9b0aeabec2463c50ca/data/sunspots-SN_m_tot_V2.0.csv",
sep = ";", header=FALSE) %>%
mutate(count = ceiling(V4)) %>%
rename(year = V3) %>%
filter(year > 2005)
count = as.integer(df$count)
time = as.numeric(df$year)
data = list(
n = length(count),
counts = count,
time = time
)
init_fun <- function() {
list(theta1 = 40, theta2 = 1.0, theta3 = 0.25)
}
fit = stan(
seed = 123,
file = "poisson.stan",
data = data,
init = init_fun,
iter = 2500
)
print(fit)
suppressPackageStartupMessages(require(ggplot2))
suppressPackageStartupMessages(require(dplyr))
df = read.csv(
"https://raw.githubusercontent.com/UBC-Stat-ML/web447/1e345149a5b698ccdf0a7e9b0aeabec2463c50ca/data/sunspots-SN_m_tot_V2.0.csv",
sep = ";", header=FALSE) %>%
mutate(count = ceiling(V4)) %>%
rename(year = V3) %>%
filter(year > 2005)
count = as.integer(df$count)
time = as.numeric(df$year)
data = list(
n = length(count),
counts = count,
time = time
)
init_fun <- function() {
list(theta1 = 40, theta2 = 1.0, theta3 = 0.25)
}
fit = stan(
seed = 123,
file = "poisson.stan",
data = data,
init = init_fun,
iter = 2500
)
print(fit)
library(bayesplot)
mcmc_hist(as.array(fit), pars = c("theta1", "theta2", "theta3"))
mcmc_pairs(as.array(fit), pars = c("theta1", "theta2", "theta3"))
# prior: Beta(alpha, beta)
alpha = 1
beta = 2
# observations: binomial draws
n_successes = 3
n_trials = 3
gamma_beta_binomial = function(p) {
if (p < 0 || p > 1) return(0.0)
dbeta(p, alpha, beta) * dbinom(x = n_successes, size = n_trials, prob = p)
}
# simple Metropolis-Hastings algorithm (normal proposal)
simple_mh = function(gamma, initial_point, n_iters) {
samples = numeric(n_iters)
dim = length(initial_point)
# TODO
for (i in 2:n_iters) {
proposal = rnorm(1, mean = samples[i - 1], sd = 0.1)
acceptance_ratio = gamma(proposal) / gamma(samples[i - 1])
if (runif(1) < acceptance_ratio) {
samples[i] = proposal
} else {
samples[i] = samples[i - 1]
}
}
return(samples)
}
# prior: Beta(alpha, beta)
alpha = 1
beta = 2
# observations: binomial draws
n_successes = 3
n_trials = 3
gamma_beta_binomial = function(p) {
if (p < 0 || p > 1) return(0.0)
dbeta(p, alpha, beta) * dbinom(x = n_successes, size = n_trials, prob = p)
}
# simple Metropolis-Hastings algorithm (normal proposal)
simple_mh = function(gamma, initial_point, n_iters) {
samples = numeric(n_iters)
dim = length(initial_point)
# TODO
for (i in 2:n_iters) {
proposal = rnorm(1, mean = samples[i - 1], sd = 0.1)
acceptance_ratio = gamma(proposal) / gamma(samples[i - 1])
if (runif(1) < acceptance_ratio) {
samples[i] = proposal
} else {
samples[i] = samples[i - 1]
}
}
return(samples)
}
set.seed(123)
n_iters = 1500
initial_point = 0.5
samples = simple_mh(gamma_beta_binomial, initial_point, n_iters)
# prior: Beta(alpha, beta)
alpha = 1
beta = 2
# observations: binomial draws
n_successes = 3
n_trials = 3
gamma_beta_binomial = function(p) {
if (p < 0 || p > 1) return(0.0)
dbeta(p, alpha, beta) * dbinom(x = n_successes, size = n_trials, prob = p)
}
# simple Metropolis-Hastings algorithm (normal proposal)
simple_mh = function(gamma, initial_point, n_iters) {
samples = numeric(n_iters)
dim = length(initial_point)
# TODO
for (i in 2:n_iters) {
proposal = rnorm(1, mean = samples[i - 1], sd = 0.1)
acceptance_ratio = gamma(proposal) / gamma(samples[i - 1])
if (runif(1) < acceptance_ratio) {
samples[i] = proposal
} else {
samples[i] = samples[i - 1]
}
}
return(samples)
}
set.seed(123)
n_iters = 1500
initial_point = 0.5
samples = simple_mh(gamma_beta_binomial, initial_point, n_iters)
runif(1) < acceptance_ratio
# prior: Beta(alpha, beta)
alpha = 1
beta = 2
# observations: binomial draws
n_successes = 3
n_trials = 3
gamma_beta_binomial = function(p) {
if (p < 0 || p > 1) return(0.0)
dbeta(p, alpha, beta) * dbinom(x = n_successes, size = n_trials, prob = p)
}
# simple Metropolis-Hastings algorithm (normal proposal)
simple_mh = function(gamma, initial_point, n_iters) {
samples = numeric(n_iters)
dim = length(initial_point)
# TODO
for (i in 2:n_iters) {
proposal = rnorm(1, mean = samples[i - 1], sd = 0.1)
acceptance_ratio = gamma(proposal) / gamma(samples[i - 1])
if (runif(1) < acceptance_ratio) {
samples[i] = proposal
} else {
samples[i] = samples[i - 1]
}
}
return(samples)
}
set.seed(123)
samples = simple_mh(gamma_beta_binomial, 0.5, 1500)
runif(1)
# prior: Beta(alpha, beta)
alpha = 1
beta = 2
# observations: binomial draws
n_successes = 3
n_trials = 3
gamma_beta_binomial = function(p) {
if (p < 0 || p > 1) return(0.0)
dbeta(p, alpha, beta) * dbinom(x = n_successes, size = n_trials, prob = p)
}
# simple Metropolis-Hastings algorithm (normal proposal)
simple_mh = function(gamma, initial_point, n_iters) {
samples = numeric(n_iters)
dim = length(initial_point)
# TODO
for (i in 2:n_iters) {
proposal = rnorm(1, mean = samples[i - 1], sd = 0.1)
acceptance_ratio = gamma(proposal) / gamma(samples[i - 1])
if (runif(1) < acceptance_ratio) {
samples[i] = proposal
} else {
samples[i] = samples[i - 1]
}
}
return(samples)
}
runif(1)
?runif
# prior: Beta(alpha, beta)
alpha = 1
beta = 2
# observations: binomial draws
n_successes = 3
n_trials = 3
gamma_beta_binomial = function(p) {
if (p < 0 || p > 1) return(0.0)
dbeta(p, alpha, beta) * dbinom(x = n_successes, size = n_trials, prob = p)
}
# simple Metropolis-Hastings algorithm (normal proposal)
simple_mh = function(gamma, initial_point, n_iters) {
samples = numeric(n_iters)
dim = length(initial_point)
# TODO
for (i in 2:n_iters) {
proposal = rnorm(1, mean = samples[i - 1], sd = 0.1)
acceptance_ratio = gamma(proposal) / gamma(samples[i - 1])
print(acceptance_ratio)
if (runif(1) < acceptance_ratio) {
samples[i] = proposal
} else {
samples[i] = samples[i - 1]
}
}
return(samples)
}
set.seed(123)
samples = simple_mh(gamma_beta_binomial, 0.5, 1500)
# prior: Beta(alpha, beta)
alpha = 1
beta = 2
# observations: binomial draws
n_successes = 3
n_trials = 3
gamma_beta_binomial = function(p) {
if (p < 0 || p > 1) return(0.0)
dbeta(p, alpha, beta) * dbinom(x = n_successes, size = n_trials, prob = p)
}
# simple Metropolis-Hastings algorithm (normal proposal)
simple_mh = function(gamma, initial_point, n_iters) {
samples = numeric(n_iters)
dim = length(initial_point)
# TODO
for (i in 2:n_iters) {
proposal = rnorm(1, mean = samples[i - 1], sd = 0.1)
print(proposal)
acceptance_ratio = gamma(proposal) / gamma(samples[i - 1])
if (runif(1) < acceptance_ratio) {
samples[i] = proposal
} else {
samples[i] = samples[i - 1]
}
}
return(samples)
}
set.seed(123)
samples = simple_mh(gamma_beta_binomial, 0.5, 1500)
# prior: Beta(alpha, beta)
alpha = 1
beta = 2
# observations: binomial draws
n_successes = 3
n_trials = 3
gamma_beta_binomial = function(p) {
if (p < 0 || p > 1) return(0.0)
dbeta(p, alpha, beta) * dbinom(x = n_successes, size = n_trials, prob = p)
}
# simple Metropolis-Hastings algorithm (normal proposal)
simple_mh = function(gamma, initial_point, n_iters) {
samples = numeric(n_iters)
dim = length(initial_point)
# TODO
for (i in 2:n_iters) {
proposal = rnorm(1, mean = samples[i - 1], sd = 0.1)
if (proposal < 0 || proposal > 1) {
samples[i] = samples[i - 1]
next
}
print(proposal)
acceptance_ratio = gamma(proposal) / gamma(samples[i - 1])
if (runif(1) < acceptance_ratio) {
samples[i] = proposal
} else {
samples[i] = samples[i - 1]
}
}
return(samples)
}
set.seed(123)
samples = simple_mh(gamma_beta_binomial, 0.5, 1500)
posterior_mean = mean(samples)
posterior_median = median(samples)
print(posterior_mean)
print(posterior_median)
