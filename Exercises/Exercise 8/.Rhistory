bind_cols(data.frame(CI_L = ci_limits[,1], CI_R = ci_limits[,2])) %>%
mutate(Inside_CI = (velocity >= CI_L & velocity <= CI_R))
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(dplyr))
fit1 = stan(
file = "STAN.stan",
data = df
)
ci_limits = quantile(extract(fit1)$y_pred, c(0.1, 0.9))
merged_df = df %>%
bind_cols(data.frame(CI_L = ci_limits[,1], CI_R = ci_limits[,2])) %>%
mutate(Inside_CI = (velocity >= CI_L & velocity <= CI_R))
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(dplyr))
fit1 = stan(
file = "STAN.stan",
data = df
)
ci_limits = extract(fit1)$y_pred
merged_df = df %>%
bind_cols(data.frame(CI_L = ci_limits[,1], CI_R = ci_limits[,2])) %>%
mutate(Inside_CI = (velocity >= CI_L & velocity <= CI_R))
extract(fit1)$y_pred
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(dplyr))
N_obs = nrow(df)
dta = list(
N  = N_obs,
xs = df$distance,
ys = df$velocity,
x_pred = df$distance
)
fit1 = stan(
file = "STAN.stan",
data = dta
)
ci_limits = quantile(extract(fit1)$y_pred, c(0.1, 0.9))
merged_df = df %>%
bind_cols(data.frame(CI_L = ci_limits[,1], CI_R = ci_limits[,2])) %>%
mutate(Inside_CI = (velocity >= CI_L & velocity <= CI_R))
extract(fit1)$y_pred
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(dplyr))
merged_df = df %>%
bind_cols(data.frame(CI_L = ci_limits[,1], CI_R = ci_limits[,2])) %>%
mutate(Inside_CI = (velocity >= CI_L & velocity <= CI_R))
knitr::opts_chunk$set(echo = TRUE)
#if you do not have the package, type install.packages("name_of_the_package")
library(knitr)
library(tseries)
library(rstan)
suppressPackageStartupMessages(require(ggplot2))
suppressPackageStartupMessages(require(dplyr))
df = read.csv(url("https://github.com/UBC-Stat-ML/web447/raw/0d6eaa346d78abe4cd125e8fc688c9074d6331d9/data/hubble-1.csv")) %>%
rename(distance = R..Mpc.) %>%
rename(velocity = v..km.sec.)
df$velocity = df$velocity/1000
N_obs = nrow(df)
N_train = N_obs-1
train_test_dta = list(
N  = N_train,
xs = df$distance[-N_obs],
ys = df$velocity[-N_obs],
x_pred = df$distance[N_obs]
)
fit = stan(
file = "STAN.stan",
data = train_test_dta
)
quantile(extract(fit)$y_pred, c(0.1, 0.9))
quantile(extract(fit)$y_pred, c(0.1, 0.9))
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(dplyr))
merged_df = df %>%
bind_cols(data.frame(CI_L = ci_limits[,1], CI_R = ci_limits[,2])) %>%
mutate(Inside_CI = (velocity >= CI_L & velocity <= CI_R))
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(dplyr))
ci_limits <- matrix(NA, nrow = N_obs, ncol = 2)
for (i in i:N_obs) {
dta = list(
N  = N_train,
xs = df$distance[-i],
ys = df$velocity[-i],
x_pred = df$distance[i]
)
fit <- stan(
file = "STAN.stan",
data = dta
)
ci_limits[i, ] <- quantile(extract(fit)$y_pred, probs = c(0.1, 0.9))
}
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(dplyr))
ci_limits <- matrix(NA, nrow = N_obs, ncol = 2)
for (i in 1:N_obs) {
dta = list(
N  = N_train,
xs = df$distance[-i],
ys = df$velocity[-i],
x_pred = df$distance[i]
)
fit <- stan(
file = "STAN.stan",
data = dta
)
ci_limits[i, ] <- quantile(extract(fit)$y_pred, probs = c(0.1, 0.9))
}
merged_df = df %>%
bind_cols(data.frame(CI_L = ci_limits[,1], CI_R = ci_limits[,2])) %>%
mutate(Inside_CI = (velocity >= CI_L & velocity <= CI_R))
merged_df %>%
ggplot(aes(x = 1:N_obs, y = velocity, ymin = CI_L, ymax = CI_R, color=Inside_CI)) +
geom_point() +
geom_errorbar() +
theme_minimal() +
labs(x = "Point", y = "Velocity")
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(dplyr))
ci_limits <- matrix(NA, nrow = N_obs, ncol = 2)
for (i in 1:N_obs) {
dta = list(
N  = N_train,
xs = df$distance[-i],
ys = df$velocity[-i],
x_pred = df$distance[i]
)
fit <- stan(
file = "STAN.stan",
data = dta
)
ci_limits[i, ] <- quantile(extract(fit)$y_pred, probs = c(0.1, 0.9))
}
merged_df = df %>%
bind_cols(data.frame(CI_L = ci_limits[,1], CI_R = ci_limits[,2])) %>%
mutate(Inside_CI = (velocity >= CI_L & velocity <= CI_R))
merged_df %>%
ggplot(aes(x = 1:N_obs, y = velocity, ymin = CI_L, ymax = CI_R, color=Inside_CI)) +
geom_point() +
geom_errorbar() +
theme_minimal() +
labs(x = "Point", y = "Velocity")
# simple Metropolis-Hastings algorithm (normal proposal)
simple_mh = function(gamma, initial_point, n_iters, proposal_sd = 1) {
samples = numeric(n_iters)
dim = length(initial_point)
current_point = initial_point
for (i in 1:n_iters) {
proposal = rnorm(dim, mean = current_point, sd = proposal_sd)
ratio = gamma(proposal) / gamma(current_point)
if (runif(1) < ratio) {
current_point = proposal
} else {
# rejection, nothing to do, i.e. we stay at the current point
}
# no matter if we reject or not, accumulate one sample
samples[i] = current_point
}
return(samples)
}
# simple Metropolis-Hastings algorithm (normal proposal)
simple_mh = function(gamma, initial_point, n_iters, proposal_sd = 1) {
samples = numeric(n_iters)
dim = length(initial_point)
current_point = initial_point
for (i in 1:n_iters) {
proposal = rnorm(dim, mean = current_point, sd = proposal_sd)
ratio = gamma(proposal) / gamma(current_point)
if (runif(1) < ratio) {
current_point = proposal
} else {
# rejection, nothing to do, i.e. we stay at the current point
}
# no matter if we reject or not, accumulate one sample
samples[i] = current_point
}
return(samples)
}
gamma = function(x) {
exp(-0.5 * x ^ 2)
}
estimate_asymptotic_variance = function(gamma, proposal_sd, C, S) {
chains = matrix(NA, nrow = S, ncol = C)
for (i in 1:C) {
chains[, c] = simple_mh(gamma, rnorm(1), S, proposal_sd)
}
chainm = colMeans(chains)
avar = var(chainm)
return(avar)
}
proposal_sds = 2 ^ seq(-10, 10)
C = 100
S = 1000
result = data.frame(proposal_sd = proposal_sds, avar = NA)
for (i in 1:length(proposal_sds)) {
result$avar[i] = estimate_asymptotic_variance(gamma, proposal_sds[i], C, S)
}
# simple Metropolis-Hastings algorithm (normal proposal)
simple_mh = function(gamma, initial_point, n_iters, proposal_sd = 1) {
samples = numeric(n_iters)
dim = length(initial_point)
current_point = initial_point
for (i in 1:n_iters) {
proposal = rnorm(dim, mean = current_point, sd = proposal_sd)
ratio = gamma(proposal) / gamma(current_point)
if (runif(1) < ratio) {
current_point = proposal
} else {
# rejection, nothing to do, i.e. we stay at the current point
}
# no matter if we reject or not, accumulate one sample
samples[i] = current_point
}
return(samples)
}
gamma = function(x) {
exp(-0.5 * x ^ 2)
}
estimate_asymptotic_variance = function(gamma, proposal_sd, C, S) {
chains = matrix(NA, nrow = S, ncol = C)
for (i in 1:C) {
chains[, c] = simple_mh(gamma, rnorm(1), S, proposal_sd)
}
chainm = colMeans(chains)
avar = var(chainm)
return(avar)
}
proposal_sds = 2 ^ seq(-10, 10)
C = 100
S = 1000
result = data.frame(proposal_sd = proposal_sds, avar = NA)
for (i in 1:length(proposal_sds)) {
result$avar[i] = estimate_asymptotic_variance(gamma, proposal_sds[i], C, S)
}
# simple Metropolis-Hastings algorithm (normal proposal)
simple_mh = function(gamma, initial_point, n_iters, proposal_sd = 1) {
samples = numeric(n_iters)
dim = length(initial_point)
current_point = initial_point
for (i in 1:n_iters) {
proposal = rnorm(dim, mean = current_point, sd = proposal_sd)
ratio = gamma(proposal) / gamma(current_point)
if (runif(1) < ratio) {
current_point = proposal
} else {
# rejection, nothing to do, i.e. we stay at the current point
}
# no matter if we reject or not, accumulate one sample
samples[i] = current_point
}
return(samples)
}
gamma = function(x) {
exp(-0.5 * x ^ 2)
}
estimate_asymptotic_variance = function(gamma, proposal_sd, C, S) {
chains = matrix(NA, nrow = S, ncol = C)
for (i in 1:C) {
initial = rnorm(1)
chains[, c] = simple_mh(gamma, initial, S, proposal_sd)
}
chainm = colMeans(chains)
avar = var(chainm)
return(avar)
}
proposal_sds = 2 ^ seq(-10, 10)
C = 100
S = 1000
result = data.frame(proposal_sd = proposal_sds, avar = NA)
for (i in 1:length(proposal_sds)) {
result$avar[i] = estimate_asymptotic_variance(gamma, proposal_sds[i], C, S)
}
# simple Metropolis-Hastings algorithm (normal proposal)
simple_mh = function(gamma, initial_point, n_iters, proposal_sd = 1) {
samples = numeric(n_iters)
dim = length(initial_point)
current_point = initial_point
for (i in 1:n_iters) {
proposal = rnorm(dim, mean = current_point, sd = proposal_sd)
ratio = gamma(proposal) / gamma(current_point)
if (runif(1) < ratio) {
current_point = proposal
} else {
# rejection, nothing to do, i.e. we stay at the current point
}
# no matter if we reject or not, accumulate one sample
samples[i] = current_point
}
return(samples)
}
g = function(x) {
exp(-0.5 * x ^ 2)
}
estimate_asymptotic_variance = function(gamma, proposal_sd, C, S) {
chains = matrix(NA, nrow = S, ncol = C)
for (i in 1:C) {
initial = rnorm(1)
chains[, c] = simple_mh(gamma, initial, S, proposal_sd)
}
chainm = colMeans(chains)
avar = var(chainm)
return(avar)
}
proposal_sds = 2 ^ seq(-10, 10)
C = 100
S = 1000
result = data.frame(proposal_sd = proposal_sds, avar = NA)
for (i in 1:length(proposal_sds)) {
result$avar[i] = estimate_asymptotic_variance(g, proposal_sds[i], C, S)
}
gamma(x)
gamma(2)
# simple Metropolis-Hastings algorithm (normal proposal)
simple_mh = function(gamma, initial_point, n_iters, proposal_sd = 1) {
samples = numeric(n_iters)
dim = length(initial_point)
current_point = initial_point
for (i in 1:n_iters) {
proposal = rnorm(dim, mean = current_point, sd = proposal_sd)
ratio = gamma(proposal) / gamma(current_point)
if (runif(1) < ratio) {
current_point = proposal
} else {
# rejection, nothing to do, i.e. we stay at the current point
}
# no matter if we reject or not, accumulate one sample
samples[i] = current_point
}
return(samples)
}
gamma = function(x) {
exp(-0.5 * x ^ 2)
}
estimate_asymptotic_variance = function(gamma, proposal_sd, C, S) {
chains = matrix(NA, nrow = S, ncol = C)
for (i in 1:C) {
initial = rnorm(1)
chains[, c] = simple_mh(gamma, initial, S, proposal_sd)
}
chainm = colMeans(chains)
avar = var(chainm)
return(avar)
}
proposal_sds = 2 ^ seq(-10, 10)
C = 100
S = 1000
result = data.frame(proposal_sd = proposal_sds, avar = NA)
for (i in 1:length(proposal_sds)) {
result$avar[i] = estimate_asymptotic_variance(gamma, proposal_sds[i], C, S)
}
estimate_asymptotic_variance(gamma, proposal_sds[1], C, S)
estimate_asymptotic_variance(gamma = gamma(), proposal_sds[1], C, S)
estimate_asymptotic_variance(gamma = gamma, proposal_sds[1], C, S)
# simple Metropolis-Hastings algorithm (normal proposal)
library(MASS)
simple_mh = function(gamma, initial_point, n_iters, proposal_sd = 1) {
samples = numeric(n_iters)
dim = length(initial_point)
current_point = initial_point
for (i in 1:n_iters) {
proposal = rnorm(dim, mean = current_point, sd = proposal_sd)
ratio = gamma(proposal) / gamma(current_point)
if (runif(1) < ratio) {
current_point = proposal
} else {
# rejection, nothing to do, i.e. we stay at the current point
}
# no matter if we reject or not, accumulate one sample
samples[i] = current_point
}
return(samples)
}
gamma = function(x) {
exp(-0.5 * x ^ 2)
}
estimate_asymptotic_variance = function(gamma, proposal_sd, C, S) {
chains = matrix(NA, nrow = S, ncol = C)
for (i in 1:C) {
initial = rnorm(1)
chains[, c] = simple_mh(gamma, initial, S, proposal_sd)
}
chainm = colMeans(chains)
avar = var(chainm)
return(avar)
}
proposal_sds = 2 ^ seq(-10, 10)
C = 100
S = 1000
result = data.frame(proposal_sd = proposal_sds, avar = NA)
for (i in 1:length(proposal_sds)) {
result$avar[i] = estimate_asymptotic_variance(gamma, proposal_sds[i], C, S)
}
library(MASS)  # For mvrnorm
# Define the unnormalized target density
target_density <- function(x) {
exp(-0.5 * x^2)  # Standard normal unnormalized density
}
# Simple Metropolis-Hastings function
simple_mh <- function(target_density, initial_point, n_iters, proposal_sd = 1) {
samples <- numeric(n_iters)
dim <- length(initial_point)
current_point <- initial_point
for (i in 1:n_iters) {
proposal <- rnorm(dim, mean = current_point, sd = proposal_sd)
ratio <- target_density(proposal) / target_density(current_point)
if (runif(1) < ratio) {
current_point <- proposal
}
samples[i] <- current_point
}
return(samples)
}
# Function to estimate asymptotic variance
estimate_asymptotic_variance <- function(target_density, proposal_sd, C, S) {
chain_samples <- matrix(NA, nrow = S, ncol = C)
# Run C independent chains with different initial points
for (c in 1:C) {
initial_point <- rnorm(1)  # Different starting points
chain_samples[, c] <- simple_mh(target_density, initial_point, S, proposal_sd)
}
# Compute the variance of the sample means across chains
chain_means <- colMeans(chain_samples)
asymptotic_var <- var(chain_means)
return(asymptotic_var)
}
# Run for different proposal_sd values
proposal_sds <- 2^seq(-10, 10)
C <- 100  # Number of chains
S <- 1000 # Samples per chain
results <- data.frame(proposal_sd = proposal_sds, asymptotic_var = NA)
for (i in 1:length(proposal_sds)) {
results$asymptotic_var[i] <- estimate_asymptotic_variance(target_density, proposal_sds[i], C, S)
}
# Print results
print(results)
# simple Metropolis-Hastings algorithm (normal proposal)
simple_mh = function(gamma, initial_point, n_iters, proposal_sd = 1) {
samples = numeric(n_iters)
dim = length(initial_point)
current_point = initial_point
for (i in 1:n_iters) {
proposal = rnorm(dim, mean = current_point, sd = proposal_sd)
ratio = gamma(proposal) / gamma(current_point)
if (runif(1) < ratio) {
current_point = proposal
} else {
# rejection, nothing to do, i.e. we stay at the current point
}
# no matter if we reject or not, accumulate one sample
samples[i] = current_point
}
return(samples)
}
gamma = function(x) {
exp(-0.5 * x ^ 2)
}
estimate_asymptotic_variance = function(gamma, proposal_sd, C, S) {
chains = matrix(NA, nrow = S, ncol = C)
for (i in 1:C) {
initial = rnorm(1)
chains[, i] = simple_mh(gamma, initial, S, proposal_sd)
}
chainm = colMeans(chains)
avar = var(chainm)
return(avar)
}
proposal_sds = 2 ^ seq(-10, 10)
C = 100
S = 1000
result = data.frame(proposal_sd = proposal_sds, avar = NA)
for (i in 1:length(proposal_sds)) {
result$avar[i] = estimate_asymptotic_variance(gamma, proposal_sds[i], C, S)
}
# simple Metropolis-Hastings algorithm (normal proposal)
simple_mh = function(gamma, initial_point, n_iters, proposal_sd = 1) {
samples = numeric(n_iters)
dim = length(initial_point)
current_point = initial_point
for (i in 1:n_iters) {
proposal = rnorm(dim, mean = current_point, sd = proposal_sd)
ratio = gamma(proposal) / gamma(current_point)
if (runif(1) < ratio) {
current_point = proposal
} else {
# rejection, nothing to do, i.e. we stay at the current point
}
# no matter if we reject or not, accumulate one sample
samples[i] = current_point
}
return(samples)
}
gamma = function(x) {
exp(-0.5 * x ^ 2)
}
estimate_asymptotic_variance = function(gamma, proposal_sd, C, S) {
chains = matrix(NA, nrow = S, ncol = C)
for (i in 1:C) {
initial = rnorm(1)
chains[, i] = simple_mh(gamma, initial, S, proposal_sd)
}
chainm = colMeans(chains)
avar = var(chainm)
return(avar)
}
proposal_sds = 2 ^ seq(-10, 10)
C = 100
S = 1000
result = data.frame(proposal_sd = proposal_sds, avar = NA)
for (i in 1:length(proposal_sds)) {
result$avar[i] = estimate_asymptotic_variance(gamma, proposal_sds[i], C, S)
}
print(result)
